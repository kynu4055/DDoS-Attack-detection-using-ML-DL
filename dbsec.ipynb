{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "LBmR6t__Y_MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DDoS Attack detection using Machine Learning and Deep Learning"
      ],
      "metadata": {
        "id": "OZ7ot50uT-KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Vm9Ga903ZMH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crUkab2YcjE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7tRNqZl3DAo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install liac-arff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6hZ7tkYoeC3",
        "outputId": "f8057a27-df73-4c0b-b0f8-8ffd3d7f58e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting liac-arff\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=b8c81998f520572da22ffd5a54732429e7b36a106364383f95dcd6491e3d7753\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/de/68/bf3972de3ecb31e32bef59a7f4c75f0687a3674c476b347c14\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: liac-arff\n",
            "Successfully installed liac-arff-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFnm5u_X-tUB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "48ff82dd-c4b7-4c74-ac4d-e136c8d78956"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadDataFormat",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadDataFormat\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e05caafa8365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/final-dataset.arff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArffDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencode_nominal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/arff.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, encode_nominal, return_type)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArffException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/arff.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, encode_nominal, return_type)\u001b[0m\n\u001b[1;32m    890\u001b[0m         '''\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             return self._decode(s, encode_nominal=encode_nominal,\n\u001b[0m\u001b[1;32m    893\u001b[0m                                 matrix_type=return_type)\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArffException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/arff.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, s, encode_nominal, matrix_type)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;31m# Alter the data object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/arff.py\u001b[0m in \u001b[0;36mdecode_rows\u001b[0;34m(self, stream, conversors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;34m\"\"\"Mixin to return a list from decode_rows instead of a generator\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DataListMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/arff.py\u001b[0m in \u001b[0;36mdecode_rows\u001b[0;34m(self, stream, conversors)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mBadDataFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadDataFormat\u001b[0m: Bad @DATA instance format in line 308563: 24.7,7,550676,21,7,ack,55,-------,8,15380,16090,884950,Switch1,clien-7,47.886346,47.886346,47.896349,0,328.167767,18049.2,55,0.00844,0,47.866339"
          ]
        }
      ],
      "source": [
        "import arff as arf\n",
        "file = open(\"/content/final-dataset.arff\") \n",
        "decoder = arf.ArffDecoder()\n",
        "data = decoder.decode(file,encode_nominal=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-VPop15_wM0"
      },
      "outputs": [],
      "source": [
        "vals=[val[0:-1] for val in data['data']]\n",
        "labels=[lab[-1] for lab in data['data']]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Z4JAphgstSFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785ce4f3-d2a9-462b-a596-55c76839128a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V5WZW2wDIJo"
      },
      "outputs": [],
      "source": [
        "from IPython.terminal.debugger import TerminalPdb\n",
        "da = set(labels)\n",
        "brac=600\n",
        "temp1=[]\n",
        "tempd=[]\n",
        "for i in da:\n",
        "  coun=0\n",
        "  while coun<brac:\n",
        "    for j in range(len(labels)):\n",
        "      if labels[j]:\n",
        "        temp1.append(labels[j])\n",
        "        tempd.append(vals[j])\n",
        "        coun+=1\n",
        "      if coun==brac:\n",
        "          break\n",
        "vals=tempd\n",
        "labels=temp1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0s8aeL0Equ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d467fe-7c90-45e7-b4b2-425cc557457d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n"
          ]
        }
      ],
      "source": [
        "l=len(vals)\n",
        "print(l)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgjA6YQ6FNED"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(vals,labels,stratify=labels,test_size=0.2,random_state=0\n",
        "                                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps-aAXvyFJ5y"
      },
      "outputs": [],
      "source": [
        "\n",
        "scaler=StandardScaler()\n",
        "x_train=scaler.fit_transform(X_train)\n",
        "x_test=scaler.transform(X_test)\n",
        "y_train=np.array(Y_train)\n",
        "y_test=np.array(Y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_R9ussUCcyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0d0dab-f914-4647-9a5c-ccb34a23e11b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(gamma='auto', kernel='sigmoid')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        " model=SVC(kernel='sigmoid',gamma='auto')\n",
        " model.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47Qd4Ow3Ifh2"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB1ECm85Iup-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9cdb96-f9ab-4e8f-8e0a-0f7ba4ffe6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88.66666666666667 %\n"
          ]
        }
      ],
      "source": [
        "print((accuracy_score(y_pred,y_test))*100,\"%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc6smC4kKVRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634a8e00-9892-4104-e406-e0831c6757ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model2 = GaussianNB()\n",
        "model2.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLKeowggKU9V"
      },
      "outputs": [],
      "source": [
        "y_pred2=model2.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okcSQ5N2KxFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ddfc97-6b80-42f3-b350-c08ab58a3229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90.16666666666666 %\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(y_pred2,y_test)*100,\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewIWVr_zY9eh"
      },
      "outputs": [],
      "source": [
        "train_x,val_x,train_y,val_y=train_test_split(x_train,y_train,stratify=y_train,test_size=0.2,random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JkBKVIAZDPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1338f3-0b47-46cb-e792-6e20898cd9c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2400, 27) (600, 27)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape,x_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SaePO6hbw9L"
      },
      "outputs": [],
      "source": [
        "columns = ['SRC_ADD', 'DES_ADD', 'PKT_ID','FROM_NODE','TO_NODE','PKT_TYPE',\n",
        "           'PKT_SIZE','FLAGS','FID','SEQ_NUMBER','NUMBER_OF_PKT',\n",
        "           'NUMBER_OF_BYTE','NODE_NAME_FROM','NODE_NAME_TO','PKT_IN','PKT_OUT',\n",
        "           'PKT_R','PKT_DELAY_NODE','PKT_RATE','BYTE_RATE','PKT_AVG_SIZE',\n",
        "           'UTILIZATION','PKT_DELAY','PKT_SEND_TIME','PKT_RESEVED_TIME',\n",
        "           'FIRST_PKT_SENT','LAST_PKT_RESEVED']\n",
        "           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le37COYGZ_D6"
      },
      "outputs": [],
      "source": [
        "model1=SVC(kernel='sigmoid',gamma='auto')\n",
        "model1.fit(train_x,train_y)\n",
        "y_val_pred1=model1.predict(val_x)\n",
        "y_val_pred1=pd.DataFrame(y_val_pred1)\n",
        "y_test_pred1=model1.predict(x_test)\n",
        "y_test_pred1=pd.DataFrame(y_test_pred1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEReE8PGbWx-"
      },
      "outputs": [],
      "source": [
        "model2=KNeighborsClassifier(n_neighbors=5)\n",
        "model2.fit(train_x,train_y)\n",
        "y_val_pred2=model1.predict(val_x)\n",
        "y_val_pred2=pd.DataFrame(y_val_pred2)\n",
        "y_test_pred2=model2.predict(x_test)\n",
        "y_test_pred2=pd.DataFrame(y_test_pred2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_HX9xlwb3_f"
      },
      "outputs": [],
      "source": [
        "model3 = GaussianNB()\n",
        "model3.fit(train_x,train_y)\n",
        "y_val_pred3=model3.predict(val_x)\n",
        "y_val_pred3=pd.DataFrame(y_val_pred3)\n",
        "y_test_pred3=model3.predict(x_test)\n",
        "y_test_pred3=pd.DataFrame(y_test_pred3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BotIqWjKcc4m"
      },
      "outputs": [],
      "source": [
        "val_input=pd.concat([pd.DataFrame(val_x,columns=columns),y_val_pred1,y_val_pred2,y_val_pred3],axis=1)\n",
        "test_input=pd.concat([pd.DataFrame(x_test,columns=columns),y_test_pred1,y_test_pred2,y_test_pred3],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF7VYhvAccrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb412a8-6b6c-4fd4-a03e-2f02b7e17a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model=RandomForestClassifier(n_estimators=200)\n",
        "model.fit(val_input,val_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpPH1IY8ccdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f82411-cd2a-46a3-c5e8-bcbea0dab89b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97.83333333333334 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "print((model.score(test_input,y_test))*100,\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import arff as arf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "file = open(r'final-dataset.arff','r')\n",
        "\n",
        "def scrape_data():\n",
        "    decoder = arf.ArffDecoder()\n",
        "    data = decoder.decode(file, encode_nominal=True)\n",
        "\n",
        "    vals = [val[0:-1] for val in data['data']]\n",
        "    labels = [label[-1] for label in data['data']]\n",
        "\n",
        "    for val in labels:\n",
        "        if labels[val] != 0:\n",
        "            labels[val] = 1\n",
        "\n",
        "    training_data = vals[0: int(.9 * len(vals))]\n",
        "    training_labels = labels[0: int(.9 * len(vals))] \n",
        "    validation_data = vals[0: int(.9 * len(vals)):]\n",
        "    validation_labels = labels[0: int(.9 * len(vals)):] \n",
        "\n",
        "    training_labels = to_categorical(training_labels, 5)\n",
        "    validation_labels = to_categorical(validation_labels, 5)\n",
        "\n",
        "    return np.asarray(training_data), np.asarray(training_labels),np.asarray(validation_data), np.asarray(validation_labels)\n",
        "\n",
        "\n",
        "def generate_model(shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(30, input_dim=shape,kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J6BKQDSnY-GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train ,label_train ,data_eval ,label_eval =scrape_data()\n",
        "\n",
        "model = generate_model(len(data_train[0]))\n",
        "model.compile(loss\n",
        "              ='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
        "history = model.fit(data_train, label_train, validation_data=(data_eval, label_eval), epochs=2, callbacks=[tensorboard])\n",
        "loss_history = history.history[\"loss\"]\n",
        "\n",
        "\n",
        "#evaluate the model performance\n",
        "print(model.evaluate(data_eval, label_eval))\n",
        "print(model.evaluate(data_train, label_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP8FaglO0ZMd",
        "outputId": "0457df44-c0d7-4a92-e322-b990691aefb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 30)                840       \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                310       \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 64)                704       \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,289\n",
            "Trainable params: 2,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "60769/60769 [==============================] - 245s 4ms/step - loss: 50.6431 - accuracy: 0.8949 - val_loss: 0.3793 - val_accuracy: 0.8960\n",
            "Epoch 2/2\n",
            "60769/60769 [==============================] - 240s 4ms/step - loss: 0.3813 - accuracy: 0.8960 - val_loss: 0.3793 - val_accuracy: 0.8960\n",
            "60769/60769 [==============================] - 102s 2ms/step - loss: 0.3793 - accuracy: 0.8960\n",
            "[0.37928733229637146, 0.8960413932800293]\n",
            "60769/60769 [==============================] - 103s 2ms/step - loss: 0.3793 - accuracy: 0.8960\n",
            "[0.37928733229637146, 0.8960413932800293]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}